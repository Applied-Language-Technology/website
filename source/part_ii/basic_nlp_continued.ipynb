{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using spaCy efficiently\n",
    "\n",
    "This section introduces you to customising the spaCy pipeline, that is, what spaCy does with text and how.\n",
    "\n",
    "After reading this section, you should know how to:\n",
    "\n",
    " - process collections of texts efficiently \n",
    " - examine and extend the spaCy pipeline\n",
    "\n",
    "Let's start by importing the spaCy library and the displacy module for drawing dependency trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library and the displacy module\n",
    "from spacy import displacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then import a language model for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x102dedd90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a small language model for English and assign it to the variable 'nlp'\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Call the variable to examine the object\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's examine the spaCy _Language_ object in greater detail.\n",
    "\n",
    "The _Language_ object is a pipeline that applies a language model to the input data.\n",
    "\n",
    "We can examine the components of a pipeline via the `pipeline` attribute of a _Language_ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1206080e0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x11fc52f40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1205a9460>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1205a95e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x120611140>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x120671a00>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a list of Python _tuples_ that consist of component names and the actual components that perform different natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing texts efficiently\n",
    "\n",
    "When working with larger volumes of data, processing the data as efficiently as possible is desirable.\n",
    "\n",
    "To illustrate the best practices of processing texts efficiently using spaCy, let's define a toy example that consists of a Python list with three example sentences from the Wikipedia article on Barack Obama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.',\n",
       " \"The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.\",\n",
       " 'The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list of example sentences\n",
    "sents = [\"On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.\", \n",
    "         \"The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.\", \n",
    "         \"The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.\"]\n",
    "\n",
    "# Call the variable to examine output\n",
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a list containing three sentences.\n",
    "\n",
    "spaCy _Language_ objects have a specific method, `pipe()`, for processing texts stored in a Python list. The `pipe()` method has been optimised for this purpose, processing texts in _batches_ rather than as individual items, which makes this method faster than a traditional `for` loop.\n",
    "\n",
    "The `pipe()` method takes a _list_ as input and returns a Python _generator_ named `pipe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Language.pipe at 0x120da35f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed the list of sentences to the pipe() method\n",
    "docs = nlp.pipe(sents)\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators are Python objects that contain other objects. When called, a generator object will yield objects contained within. \n",
    "\n",
    "To retrieve all objects in a generator, we must cast the output into another object type, such as a list. You can think of the list as a data structure that is able to collect the generator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.,\n",
       " The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.,\n",
       " The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cast the pipe generator into a list\n",
    "docs = list(docs)\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a list of spaCy _Doc_ objects for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging noun phrases\n",
    "\n",
    "As the [previous section](basic_nlp.ipynb) showed, tasks such as part-of-speech tagging and dependency parsing make predictions about individual _Tokens_ and their properties, such as part-of-speech tags or syntactic dependencies.\n",
    "\n",
    "Occasionally, however, it may be more beneficial to operate with larger linguistic units, so such as noun phrases that consist of multiple _Tokens_.\n",
    "\n",
    "spaCy provides access to noun phrases via the attribute `noun_chunks` of a _Doc_ object.\n",
    "\n",
    "Let's print out the noun chunks in each _Doc_ object contained in the list `docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October\n",
      "the Obama administration\n",
      "a Bush administration program\n",
      "nuclear weapons production\n",
      "The 'Complex Modernization' initiative\n",
      "two existing nuclear sites\n",
      "new bomb parts\n",
      "The administration\n",
      "new plutonium pits\n",
      "the Los Alamos lab\n",
      "New Mexico\n",
      "enriched uranium processing\n",
      "the Y-12 facility\n",
      "Oak Ridge\n",
      "Tennessee\n"
     ]
    }
   ],
   "source": [
    "# Define the first for-loop over the list 'docs'\n",
    "# The variable 'doc' refers to items in the list\n",
    "for doc in docs:\n",
    "    \n",
    "    # Loop over each noun chunk in the Doc object\n",
    "    for noun_chunk in doc.noun_chunks:\n",
    "        \n",
    "        # Print noun chunk\n",
    "        print(noun_chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two `for` loops return several noun phrases that consist of multiple _Tokens_.\n",
    "\n",
    "For merging noun phrases into a single _Token_, spaCy provides a function named `merge_noun_tokens` that can be added to the pipeline stored in a _Language_ object using the `add_pipe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_noun_chunks(doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add component that merges noun phrases into single Tokens\n",
    "nlp.add_pipe('merge_noun_chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we do not need to reassign the _Language_ object under `nlp` to the same variable to update its contents. The `add_pipe` method adds the component to the _Language_ object automatically. \n",
    "\n",
    "We can verify that the component was added successfully by examining the `pipeline` attribute under the _Language_ object `nlp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1206080e0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x11fc52f40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1205a9460>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1205a95e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x120611140>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x120671a00>),\n",
       " ('merge_noun_chunks',\n",
       "  <function spacy.pipeline.functions.merge_noun_chunks(doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the pipeline components\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the final tuple in the list consists of the `merge_noun_chunks` function.\n",
    "\n",
    "To examine the consequences of adding this function to the pipeline, let's process the three example sentences again using the `pipe()` method of the _Language_ object `nlp`.\n",
    "\n",
    "We overwrite the previous results stored under the same variable by assigning the output to the variable `docs`.\n",
    "\n",
    "Note that we also cast the result into a list by wrapping the _Language_ object and the `pipe()` method into a `list()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[On October 1, 2009, the Obama administration went ahead with a Bush administration program, increasing nuclear weapons production.,\n",
       " The 'Complex Modernization' initiative expanded two existing nuclear sites to produce new bomb parts.,\n",
       " The administration built new plutonium pits at the Los Alamos lab in New Mexico and expanded enriched uranium processing at the Y-12 facility in Oak Ridge, Tennessee.]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the Language object 'nlp' to the list of sentences under 'sents'\n",
    "docs = list(nlp.pipe(sents))\n",
    "\n",
    "# Call the variable to examine the output\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superficially, everything remains the same: the list contains three _Doc_ objects. \n",
    "\n",
    "However, if we loop over the _Tokens_ in the first _Doc_ object in the list, which can be accessed using brackets at position zero, e.g. `[0]`, we can see that the noun phrases are now merged and tagged using the label `NOUN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On ADP\n",
      "October PROPN\n",
      "1 NUM\n",
      ", PUNCT\n",
      "2009 NUM\n",
      ", PUNCT\n",
      "the Obama administration NOUN\n",
      "went VERB\n",
      "ahead ADV\n",
      "with ADP\n",
      "a Bush administration program NOUN\n",
      ", PUNCT\n",
      "increasing VERB\n",
      "nuclear weapons production NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Loop over Tokens in the first Doc object in the list\n",
    "for token in docs[0]:\n",
    "    \n",
    "    # Print out the Token and its part-of-speech tag\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging noun phrases using the label `NOUN` is a reasonable approximation, as noun phrases typically take on similar grammatical functions as nouns.\n",
    "\n",
    "As rendering the syntactic parse using displacy shows, merging the noun phrases simplifies the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"861f5324d744473b9a77c27870d7c637-0\" class=\"displacy\" width=\"1975\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">On</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">October</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">1,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">2009,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the Obama administration</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">went</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">ahead</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">a Bush administration program,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">increasing</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">nuclear weapons production.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 925.0,2.0 925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M385.0,354.0 L393.0,342.0 377.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,354.0 L573.0,342.0 557.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-6\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,354.0 L1273.0,342.0 1257.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-8\" stroke-width=\"2px\" d=\"M945,352.0 C945,89.5 1620.0,89.5 1620.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1620.0,354.0 L1628.0,342.0 1612.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-861f5324d744473b9a77c27870d7c637-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-861f5324d744473b9a77c27870d7c637-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(docs[0], style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the noun phrases are now represented by single *Tokens*, the noun chunks are still available under the `noun_chunks` attribute of the *Doc* object.\n",
    "\n",
    "As shown below, spaCy stores noun chunks as *Spans*, whose `start` attribute determines the index of the Token where the _Span_ starts, while the `end` attribute determines where the _Span_ has ended.\n",
    "\n",
    "This information is useful, if the syntactic analysis reveals patterns that warrant a closer examination of the noun chunks and their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "October <class 'spacy.tokens.span.Span'> 1 2\n",
      "the Obama administration <class 'spacy.tokens.span.Span'> 6 7\n",
      "a Bush administration program <class 'spacy.tokens.span.Span'> 10 11\n",
      "nuclear weapons production <class 'spacy.tokens.span.Span'> 13 14\n"
     ]
    }
   ],
   "source": [
    "# Loop over the noun chunks in the first Doc object [0] in the list 'docs'\n",
    "for noun_chunk in docs[0].noun_chunks:\n",
    "    \n",
    "    # Print out noun chunk, its type, the Token where the chunks starts and where it ends\n",
    "    print(noun_chunk, type(noun_chunk), noun_chunk.start, noun_chunk.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging named entities\n",
    "\n",
    "Named entities can be merged in the same way as noun phrases by providing `merge_entities` to the `add_pipe()` method of the *Language* object.\n",
    "\n",
    "Let's start by removing the `merge_noun_chunks` function from the pipeline.\n",
    "\n",
    "The `remove_pipe()` method can be used to remove a pipeline component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'merge_noun_chunks' function from the pipeline under 'nlp'\n",
    "nlp.remove_pipe('merge_noun_chunks')\n",
    "\n",
    "# Process the original sentences again\n",
    "docs = list(nlp.pipe(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method returns a tuple containing the name of the removed component (in this case, a function) and the component itself.\n",
    "\n",
    "We can verify this by calling the `pipeline` attribute of the _Language_ object `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1206080e0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x11fc52f40>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1205a9460>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1205a95e0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x120611140>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x120671a00>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's add the `merge_entities` component to the pipeline under `nlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'merge_entities' function to the pipeline\n",
    "nlp.add_pipe('merge_entities')\n",
    "\n",
    "# Process the data again\n",
    "docs = list(nlp.pipe(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the result by looping over the _Tokens_ in the third _Doc_ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET\n",
      "administration NOUN\n",
      "built VERB\n",
      "new ADJ\n",
      "plutonium NOUN\n",
      "pits NOUN\n",
      "at ADP\n",
      "the DET\n",
      "Los Alamos PROPN\n",
      "lab NOUN\n",
      "in ADP\n",
      "New Mexico PROPN\n",
      "and CCONJ\n",
      "expanded VERB\n",
      "enriched ADJ\n",
      "uranium NOUN\n",
      "processing NOUN\n",
      "at ADP\n",
      "the DET\n",
      "Y-12 PROPN\n",
      "facility NOUN\n",
      "in ADP\n",
      "Oak Ridge PROPN\n",
      ", PUNCT\n",
      "Tennessee PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "# Loop over Tokens in the third Doc object in the list\n",
    "for token in docs[2]:\n",
    "    \n",
    "    # Print out the Token and its part-of-speech tag\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entities that consist of multiple *Tokens*, as exemplified by place names such as \"Los Alamos\" and \"New Mexico\", have been merged into single *Tokens*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section should have given you an idea of how spaCy can be modified and used effectively.\n",
    "\n",
    "The [following section](evaluating_nlp.ipynb) introduces you to evaluating the performance of language models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
